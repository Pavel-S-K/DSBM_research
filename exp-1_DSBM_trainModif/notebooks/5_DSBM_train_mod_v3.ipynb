{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe0fe3-93e9-4ca1-aff0-49a8f0b225d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import copy\n",
    "import ot\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import sys\n",
    "import os, shutil\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8dad29-f78f-4dae-80b6-54b8414a91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт пользовательских функций\n",
    "sys.path.append('..')\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "# Load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set autoreload mode\n",
    "%autoreload 2\n",
    "\n",
    "from src.ScoreNetwork import ScoreNetwork\n",
    "from src.DSBM_model_mod_v3 import DSBM, train_dsbm, train\n",
    "from src.generate_gaussian_cloud import generate_gaussian_cloud\n",
    "from src.test_fn import test_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d0a2d-b1a3-48ba-96b4-97eab6019960",
   "metadata": {},
   "source": [
    "## Загрузка и задание параметров эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6614ab-a8ea-4beb-b117-eed4de1ee0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт параметров модели и данных\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../configurations\"):\n",
    "    \n",
    "    cfg: DictConfig = compose(config_name=\"gaussian_MOD_v3.yaml\")\n",
    "\n",
    "if cfg.get(\"seed\"):\n",
    "    pl.seed_everything(cfg.seed, workers=True)\n",
    "print(cfg)\n",
    "\n",
    "RESULT_DIR = '../results_v3/' + cfg.paths.experiments_dir_name\n",
    "\n",
    "# Вариант 1: Явная проверка с пользовательской ошибкой\n",
    "if os.path.exists(RESULT_DIR):\n",
    "    print(f\"\\n\\nДиректория {RESULT_DIR} уже существует. Сгенерирована новая директория с индексом\")\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    RESULT_DIR = f'{RESULT_DIR}_{timestamp}'\n",
    "    \n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "RESULT_DIR = RESULT_DIR + '/'\n",
    "\n",
    "OmegaConf.save(cfg, RESULT_DIR + 'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa770c1d-93e4-4e7e-94fe-da5e7b6b59d9",
   "metadata": {},
   "source": [
    "## Генерация train-test датасетов (двух гауссиан)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018dcee-2540-4c64-8d60-178bc3c14e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация датасетов\n",
    "\n",
    "# train\n",
    "x0 = generate_gaussian_cloud(\n",
    "    vars_diag=cfg.x0_vars_diag,  \n",
    "    cov_pairs=cfg.x0_cov_pairs, \n",
    "    mean=cfg.x0_mean, \n",
    "    dataset_size=cfg.dataset_size, \n",
    "    plot=True\n",
    ")  \n",
    "\n",
    "x1 = generate_gaussian_cloud(\n",
    "    vars_diag=cfg.x1_vars_diag,  \n",
    "    cov_pairs=cfg.x1_cov_pairs, \n",
    "    mean=cfg.x1_mean, \n",
    "    dataset_size=cfg.dataset_size, \n",
    "    plot=True\n",
    ")  \n",
    "\n",
    "\n",
    "# test\n",
    "x0_test = generate_gaussian_cloud(\n",
    "    vars_diag=cfg.x0_vars_diag,  \n",
    "    cov_pairs=cfg.x0_cov_pairs, \n",
    "    mean=cfg.x0_mean, \n",
    "    dataset_size=cfg.test_dataset_size, \n",
    "    plot=False\n",
    ")  \n",
    "\n",
    "x1_test = generate_gaussian_cloud(\n",
    "    vars_diag=cfg.x1_vars_diag,  \n",
    "    cov_pairs=cfg.x1_cov_pairs, \n",
    "    mean=cfg.x1_mean, \n",
    "    dataset_size=cfg.test_dataset_size, \n",
    "    plot=False\n",
    ")  \n",
    "\n",
    "\n",
    "# Приведение к требуемому типу\n",
    "x0 = torch.tensor(x0).to(torch.float32).to(device)\n",
    "x1 = torch.tensor(x1).to(torch.float32).to(device)\n",
    "x0_test = torch.tensor(x0_test).to(torch.float32).to(device)\n",
    "x1_test = torch.tensor(x1_test).to(torch.float32).to(device)\n",
    "\n",
    "x_pairs = torch.stack([x0, x1], dim=1).to(device)\n",
    "x_pairs_test = torch.stack([x0_test, x1_test], dim=1).to(device)\n",
    "\n",
    "\n",
    "print('Гауссиана 0:')\n",
    "print('mean: ', x0.mean().item())\n",
    "print('var: ', x0.var().item())\n",
    "print('cnt: ', x0.shape[0])\n",
    "print('dim: ', x0.shape[1])\n",
    "\n",
    "print('\\nГауссиана 1:')\n",
    "print('mean: ', x1.mean().item())\n",
    "print('var: ', x1.var().item())\n",
    "print('cnt: ', x1.shape[0])\n",
    "print('dim: ', x1.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62d04b-adb2-4586-ac1f-41343fa65847",
   "metadata": {},
   "source": [
    "## Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44b18d-57d5-4406-9dfa-2e09dbc63f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение структуры модели\n",
    "\n",
    "activation_fn = hydra.utils.get_class(cfg.activation_fn)()\n",
    "hidden_size = cfg.net_hidden_layer_width\n",
    "dim = cfg.dim\n",
    "net_fn = partial(ScoreNetwork, input_dim=dim+1, layer_widths=[hidden_size, hidden_size, dim], activation_fn=activation_fn)  \n",
    "\n",
    "num_steps = cfg.num_steps\n",
    "sigma = cfg.sigma\n",
    "inner_iters = cfg.inner_iters\n",
    "batch_size = cfg.batch_size\n",
    "\n",
    "\n",
    "model = DSBM(net_fwd=net_fn().to(device), \n",
    "             net_bwd=net_fn().to(device), \n",
    "             num_steps=num_steps, sig=sigma, first_coupling=cfg.first_coupling)\n",
    "train_fn = train_dsbm\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.net_fwd.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: <{n_parameters}>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513b52e-a3fa-425a-ab01-a8bc675d547a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c3a36-a4e2-44dd-b2e7-04a882da3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "\n",
    "all_data = torch.stack([x0, x1], dim=1).to(device) # Формируем полный пулл данных, которые учитываем для обучения скалера\n",
    "model.normalizer.fit(all_data)\n",
    "model.normalizer_fitted = True # Флаг для модели, что задействован скалер\n",
    "model.sig = sigma * model.normalizer.A # Масштабирем sigma\n",
    "x0_norm= model.normalizer.normalize(x0.clone())\n",
    "x1_norm = model.normalizer.normalize(x1.clone())\n",
    "x_pairs = torch.stack([x0_norm, x1_norm], dim=1).to(device) # Формируем обучающую пару\n",
    "\n",
    "print('Гауссиана 0:')\n",
    "print('mean: ', x0_norm.mean().item())\n",
    "print('var: ', x0_norm.var().item())\n",
    "print('cnt: ', x0_norm.shape[0])\n",
    "print('dim: ', x0_norm.shape[1])\n",
    "\n",
    "print('\\nГауссиана 1:')\n",
    "print('mean: ', x1_norm.mean().item())\n",
    "print('var: ', x1_norm.var().item())\n",
    "print('cnt: ', x1_norm.shape[0])\n",
    "print('dim: ', x1_norm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440d61-2d43-4df6-b4fa-587ec70a370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = dict()\n",
    "logs['optimal_result_dict'] = {'mean': x0_test.mean(0).mean(0).item(), 'var': x0_test.var(0).mean(0).item(), 'cov': (np.sqrt(5) - 1) / 2}\n",
    "logs['time_list'] = []\n",
    "logs['time_list_res'] = []\n",
    "logs['result_list'] = {k: [] for k in logs['optimal_result_dict'].keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d7310-9e09-4208-98e5-8efcb93e1dbb",
   "metadata": {},
   "source": [
    "## Train-test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a78814-d9b2-4f4d-ae3e-86bde26e7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test\n",
    "model, logs = train(cfg, model, x_pairs, x_pairs_test, logs, 20, 1e-5, RESULT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee93a1-83d0-429d-93ff-f4f40086cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val\n",
    "df_SWD = test_fn(cfg, model, N_samples = 10)\n",
    "df_SWD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6809def-bb14-45c9-b181-ad30f7fcb694",
   "metadata": {},
   "source": [
    "# Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584e0e1-5bad-47b3-94c3-c1694b26b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результаты\n",
    "# Сохраняем последнюю версию модели\n",
    "torch.save(model.state_dict(), RESULT_DIR + 'best_model.pt')\n",
    "\n",
    "df_result = pd.DataFrame(logs['result_list'])\n",
    "df_result.to_csv(RESULT_DIR + 'df_result.csv')\n",
    "df_result.to_pickle(RESULT_DIR+ 'df_result.pkl')\n",
    "\n",
    "df_time = pd.DataFrame(logs['time_list'])\n",
    "df_time.to_csv(RESULT_DIR + 'df_time.csv')\n",
    "df_time.to_pickle(RESULT_DIR+ 'df_time.pkl')\n",
    "\n",
    "df_SWD.to_csv(RESULT_DIR + 'df_wasserstein_distance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
