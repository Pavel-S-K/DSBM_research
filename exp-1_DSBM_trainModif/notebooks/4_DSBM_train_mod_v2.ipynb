{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe0fe3-93e9-4ca1-aff0-49a8f0b225d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import copy\n",
    "import ot\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import sys\n",
    "import os, shutil\n",
    "import time\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8dad29-f78f-4dae-80b6-54b8414a91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт пользовательских функций\n",
    "from src.ScoreNetwork import ScoreNetwork\n",
    "from src.DSBM_model_mod_v2 import DSBM, train_dsbm\n",
    "from src.draw_plot import draw_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d0a2d-b1a3-48ba-96b4-97eab6019960",
   "metadata": {},
   "source": [
    "## Загрузка и задание параметров эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6614ab-a8ea-4beb-b117-eed4de1ee0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт параметров модели и данных\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../configurations\"):\n",
    "    \n",
    "    cfg: DictConfig = compose(config_name=\"gaussian_MOD_v2.yaml\")\n",
    "\n",
    "if cfg.get(\"seed\"):\n",
    "    pl.seed_everything(cfg.seed, workers=True)\n",
    "print(cfg)\n",
    "\n",
    "RESULT_DIR = '../results_v2/' + cfg.paths.experiments_dir_name + '_MOD' + '/'\n",
    "if os.path.exists(RESULT_DIR):\n",
    "    shutil.rmtree(RESULT_DIR)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "OmegaConf.save(cfg, RESULT_DIR + 'config.yaml')\n",
    "\n",
    "\n",
    "# Параметры обучения\n",
    "device = 'cpu'\n",
    "dataset_size = 10000\n",
    "test_dataset_size = 10000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107df4fc-3d08-4cfc-81c6-5461803ee40c",
   "metadata": {},
   "source": [
    "## Генерация train-test датасетов (двух гауссиан)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061d32b-a5ce-47c1-a91d-e722272d740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация Гауссиан\n",
    "\n",
    "a = cfg.a\n",
    "dim = cfg.dim\n",
    "initial_model = Normal(-a * torch.ones((dim, )), 1)\n",
    "target_model = Normal(a * torch.ones((dim, )), 1)\n",
    "\n",
    "x0 = initial_model.sample([dataset_size])\n",
    "x1 = target_model.sample([dataset_size])\n",
    "x_pairs = torch.stack([x0, x1], dim=1).to(device)\n",
    "\n",
    "x0_test = initial_model.sample([test_dataset_size])\n",
    "x1_test = target_model.sample([test_dataset_size])\n",
    "x0_test = x0_test.to(device)\n",
    "x1_test = x1_test.to(device)\n",
    "\n",
    "# Сохраняем сформированные датасеты\n",
    "torch.save({'x0': x0, 'x1': x1, 'x0_test': x0_test, 'x1_test': x1_test}, RESULT_DIR + \"data.pt\")\n",
    "x_test_dict = {'f': x0_test, 'b': x1_test}\n",
    "\n",
    "print('Гауссиана 0:')\n",
    "print('mean: ', x0.mean().item())\n",
    "print('var: ', x0.var().item())\n",
    "print('cnt: ', x0.shape[0])\n",
    "print('dim: ', x0.shape[1])\n",
    "\n",
    "print('\\nГауссиана 1:')\n",
    "print('mean: ', x1.mean().item())\n",
    "print('var: ', x1.var().item())\n",
    "print('cnt: ', x1.shape[0])\n",
    "print('dim: ', x1.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62d04b-adb2-4586-ac1f-41343fa65847",
   "metadata": {},
   "source": [
    "## Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44b18d-57d5-4406-9dfa-2e09dbc63f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение структуры модели\n",
    "\n",
    "activation_fn = hydra.utils.get_class(cfg.activation_fn)()\n",
    "hidden_size = cfg.net_hidden_layer_width\n",
    "net_fn = partial(ScoreNetwork, input_dim=dim+1, layer_widths=[hidden_size, hidden_size, dim], activation_fn=activation_fn)  \n",
    "\n",
    "num_steps = cfg.num_steps\n",
    "sigma = cfg.sigma\n",
    "inner_iters = cfg.inner_iters\n",
    "outer_iters = cfg.outer_iters\n",
    "\n",
    "if cfg.model_name == \"dsbm\":\n",
    "    model = DSBM(net_fwd=net_fn().to(device), \n",
    "                 net_bwd=net_fn().to(device), \n",
    "                 num_steps=num_steps, sig=sigma, first_coupling=cfg.first_coupling)\n",
    "    train_fn = train_dsbm\n",
    "else:\n",
    "    raise ValueError(\"Wrong model_name!\")\n",
    "\n",
    "model_list = []\n",
    "time_list = []\n",
    "time_list_res = []\n",
    "optimal_result_dict = {'mean': x0_test.mean(0).mean(0).item(), 'var': x0_test.var(0).mean(0).item(), 'cov': (np.sqrt(5) - 1) / 2}\n",
    "result_list = {k: [] for k in optimal_result_dict.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513b52e-a3fa-425a-ab01-a8bc675d547a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a71860-611a-444e-b3aa-5b336a19cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "\n",
    "all_data = torch.stack([x0, x1], dim=1).to(device) # Формируем полный пулл данных, которые учитываем для обучения скалера\n",
    "model.normalizer.fit(all_data)\n",
    "model.normalizer_fitted = True # Флаг для модели, что задействован скалер\n",
    "model.sig = sigma * model.normalizer.A # Масштабирем sigma\n",
    "x0_norm= model.normalizer.normalize(x0.clone())\n",
    "x1_norm = model.normalizer.normalize(x1.clone())\n",
    "x_pairs = torch.stack([x0_norm, x1_norm], dim=1).to(device) # Формируем обучающую пару\n",
    "\n",
    "print('Гауссиана 0:')\n",
    "print('mean: ', x0_norm.mean().item())\n",
    "print('var: ', x0_norm.var().item())\n",
    "print('cnt: ', x0_norm.shape[0])\n",
    "print('dim: ', x0_norm.shape[1])\n",
    "\n",
    "print('\\nГауссиана 1:')\n",
    "print('mean: ', x1_norm.mean().item())\n",
    "print('var: ', x1_norm.var().item())\n",
    "print('cnt: ', x1_norm.shape[0])\n",
    "print('dim: ', x1_norm.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d7310-9e09-4208-98e5-8efcb93e1dbb",
   "metadata": {},
   "source": [
    "## Train-test loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4d552-1d50-453b-807c-a48db84464d9",
   "metadata": {},
   "source": [
    "#### Training loop можно запускать повторно для дообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24052c69-7c24-4bbb-bd8a-c48b59e153fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "it = 1\n",
    "\n",
    "# Параметры текущиего цикла обучения\n",
    "lr = 1e-4\n",
    "outer_iters = 100\n",
    "\n",
    "# train loop\n",
    "with tqdm(total=outer_iters, desc=\"Training Loop iter\") as pbar:\n",
    "    while it <= outer_iters:\n",
    "        for fb in cfg.fb_sequence:\n",
    "          start_time = time.time()\n",
    "    \n",
    "          # train\n",
    "          if len(model_list) == 0:\n",
    "            prev_model = None\n",
    "            first_it = True\n",
    "          else:\n",
    "            prev_model = model_list[-1][\"model\"].eval()\n",
    "            first_it = False\n",
    "              \n",
    "          model, loss_curve = train_fn(model, x_pairs, batch_size, inner_iters, prev_model=prev_model, fb=fb, first_it=first_it, lr=lr)\n",
    "          end_time = time.time()\n",
    "\n",
    "          time_list.append(end_time-start_time)\n",
    "          model_list.append({'fb': fb, 'model': copy.deepcopy(model).eval()})\n",
    "          \n",
    "            \n",
    "          # test - только для модели b -> f\n",
    "          # оцениваем на каждой 10 итерации\n",
    "          if (it%10 == 0) or (it==2):\n",
    "              \n",
    "              i = len(model_list)\n",
    "              traj = model.eval().sample_sde(zstart=x1_test, fb='b', N=cfg.num_steps)\n",
    "              \n",
    "              draw_plot(traj, z0=x0_test, z1=x1_test)\n",
    "              plt.savefig(RESULT_DIR + f\"iter_{i}-b.png\")\n",
    "              plt.close()\n",
    "              #time_list_res.append(int(list(accumulate(time_list))[-1]))\n",
    "              time_list_res.append(int(np.sum(time_list)))\n",
    "              result_list['mean'].append(traj[-1].mean(0).mean(0).item())\n",
    "              result_list['var'].append(traj[-1].var(0).mean(0).item())\n",
    "              result_list['cov'].append(torch.cov(torch.cat([traj[0], traj[-1]], dim=1).T)[dim:, :dim].diag().mean(0).item())\n",
    "\n",
    "              for j, k in enumerate(result_list.keys()):\n",
    "                  plt.plot(np.arange(len(result_list[k]))*10, result_list[k], label=f\"{cfg.model_name}-{cfg.net_name}\")\n",
    "                  plt.plot(np.arange(len(result_list[k]))*10, optimal_result_dict[k] * np.ones(len(result_list[k])), label=\"optimal\", linestyle=\"--\")\n",
    "                  plt.title(k.capitalize())\n",
    "                  if j == 0:\n",
    "                      plt.legend()\n",
    "                  plt.savefig(RESULT_DIR +  f\"convergence_{k}.png\")\n",
    "                  plt.close()\n",
    "\n",
    "              for j, k in enumerate(result_list.keys()):\n",
    "                  plt.plot(time_list_res, result_list[k], label=f\"{cfg.model_name}-{cfg.net_name}\")\n",
    "                  plt.plot(time_list_res, optimal_result_dict[k] * np.ones(len(result_list[k])), label=\"optimal\", linestyle=\"--\")\n",
    "                  plt.xlabel(\"Время обучения, сек.\")\n",
    "                  plt.title(k.capitalize())\n",
    "                  if j == 0:\n",
    "                      plt.legend()\n",
    "                  plt.savefig(RESULT_DIR +  f\"convergence_{k}_inTime.png\")\n",
    "                  plt.close()\n",
    "          else:\n",
    "              pass\n",
    "    \n",
    "          it += 1\n",
    "          pbar.update(1)\n",
    "          if it > outer_iters:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78aa424-0763-4802-90ea-8d0ccc42893a",
   "metadata": {},
   "source": [
    "## Проведение тестов инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c8edd-1def-4e45-ab2f-aa9905531c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_wasserstein_distance(\n",
    "    samples_hat: np.ndarray,\n",
    "    samples_target: np.ndarray,\n",
    "    max_points: int = 2048,\n",
    ") -> float:\n",
    "    samples_hat = np.asarray(samples_hat, dtype=np.float64)\n",
    "    samples_target = np.asarray(samples_target, dtype=np.float64)\n",
    "\n",
    "    n_hat = samples_hat.shape[0]\n",
    "    n_target = samples_target.shape[0]\n",
    "\n",
    "    if n_hat > max_points:\n",
    "        idx = np.random.choice(n_hat, max_points, replace=False)\n",
    "        samples_hat = samples_hat[idx]\n",
    "        n_hat = max_points\n",
    "    if n_target > max_points:\n",
    "        idx = np.random.choice(n_target, max_points, replace=False)\n",
    "        samples_target = samples_target[idx]\n",
    "        n_target = max_points\n",
    "\n",
    "    a = np.full(n_hat, 1.0 / n_hat, dtype=np.float64)\n",
    "    b = np.full(n_target, 1.0 / n_target, dtype=np.float64)\n",
    "    cost = ot.dist(samples_hat, samples_target, metric=\"euclidean\")\n",
    "    cost = cost * cost\n",
    "    wasserstein_squared = ot.emd2(a, b, cost)\n",
    "    return float(np.sqrt(max(wasserstein_squared, 0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8c117-8836-450e-93a7-6c0b137806d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_SWD = []\n",
    "for i in range(10):\n",
    "    a = cfg.a\n",
    "    dim = cfg.dim\n",
    "    target_model = Normal(-a * torch.ones((dim, )), 1)\n",
    "    initial_model = Normal(a * torch.ones((dim, )), 1)\n",
    "    \n",
    "    x0 = initial_model.sample([dataset_size])\n",
    "    x1 = target_model.sample([dataset_size])\n",
    "\n",
    "    start_time = time.time()\n",
    "    traj = model.eval().sample_sde(zstart=x0, fb='b', N=cfg.num_steps)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    end_mean = traj[-1].mean(0).mean(0).item()\n",
    "    end_var =  traj[-1].var(0).mean(0).item()\n",
    "    traj_cov = torch.cov(torch.cat([traj[0], traj[-1]], dim=1).T)[dim:, :dim].diag().mean(0).item()\n",
    "    \n",
    "    W = empirical_wasserstein_distance(traj[-1].numpy(), x1_test.numpy())\n",
    "\n",
    "    results_SWD.append({\n",
    "            'sample_№': i,\n",
    "            'inference_time': end_time - start_time,\n",
    "            '2-wasserstein_distance': W,\n",
    "            'mean': end_mean,\n",
    "            'var': end_var,\n",
    "            'cov': traj_cov\n",
    "        })\n",
    "\n",
    "df_SWD = pd.DataFrame(results_SWD)\n",
    "df_SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584e0e1-5bad-47b3-94c3-c1694b26b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результаты\n",
    "# Сохраняем последнюю версию модели\n",
    "torch.save(model_list[-1]['model'].state_dict(), RESULT_DIR + 'best_model.pt')\n",
    "\n",
    "df_result = pd.DataFrame(result_list)\n",
    "df_result.to_csv(RESULT_DIR + 'df_result.csv')\n",
    "df_result.to_pickle(RESULT_DIR+ 'df_result.pkl')\n",
    "\n",
    "df_time = pd.DataFrame(time_list)\n",
    "df_time.to_csv(RESULT_DIR + 'df_time.csv')\n",
    "df_time.to_pickle(RESULT_DIR+ 'df_time.pkl')\n",
    "\n",
    "df_SWD.to_csv(RESULT_DIR + 'df_wasserstein_distance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff54a3-793d-4ff5-9edc-a356d3593d8e",
   "metadata": {},
   "source": [
    "## Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61fc96-14b9-4d6a-8602-cfd3634f5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(target, fact, rnd, title):\n",
    "    target = np.round(target,rnd)\n",
    "    fact = np.round(fact,rnd)\n",
    "    res = np.round(target - fact,rnd)\n",
    "    res_percent = np.round(100*(target - fact)/target, 0)\n",
    "    print('\\n',title,':')\n",
    "    print(f'target: {target}')\n",
    "    print(f'fact: {fact}')\n",
    "    print(f'res: {res}')\n",
    "    print(f'res %: {res_percent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50a261-ff37-45af-a89b-5f51fe7d3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Среднее время выполнения операции: {np.round(df_time.mean(),0).item()} сек.')\n",
    "print(f'Суммарное время обучения: {np.round(df_time.sum(),0).item()} сек. или {np.round(df_time.sum()/60,0).item()}  мин.')\n",
    "\n",
    "print_res(x0_test.mean(0).mean(0).item(), df_result['mean'].iloc[-1], 4, 'mean')\n",
    "print_res(x0_test.var(0).mean(0).item(), df_result['var'].iloc[-1], 4, 'var')\n",
    "print_res((np.sqrt(5) - 1) / 2, df_result['cov'].iloc[-1], 4, 'cov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393acc16-e904-4da7-9a7e-9e98ae77891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread(RESULT_DIR + 'convergence_cov.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(RESULT_DIR + 'convergence_mean.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(RESULT_DIR + 'convergence_var.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb64f8-784f-4caf-a287-de22cecb4655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930dfe1c-d49c-483a-a03c-d50c03417793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
